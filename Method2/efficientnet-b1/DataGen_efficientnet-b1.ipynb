{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.train_data_size = (0,57)\n",
    "        self.test_data_size = (57, 63)\n",
    "        self.ROOT_DATA_PATH = 'Task06_Lung/Preprocessed/train/data/'\n",
    "        self.ROOT_LABEL_PATH = 'Task06_Lung/Preprocessed/train/label/'\n",
    "        self.TEST_DATA_PATH = 'Task06_Lung/Preprocessed/test/data/'\n",
    "        self.TEST_LABEL_PATH = 'Task06_Lung/Preprocessed/test/label/'\n",
    "\n",
    "    def __len__(self):\n",
    "        for _, __, files in os.walk(self.ROOT_DATA_PATH):\n",
    "            return len(files)\n",
    "\n",
    "    def train_generate(self, size):\n",
    "        while True:\n",
    "            batch_count = 0\n",
    "            yield_list = []\n",
    "            for i in range(size):\n",
    "                    ct = np.load(self.ROOT_DATA_PATH + str(i) + \".npy\")\n",
    "                    mask = np.load(self.ROOT_LABEL_PATH + str(i) + \".npy\")\n",
    "\n",
    "                    ct = torch.Tensor(ct)\n",
    "                    mask = torch.Tensor(mask)\n",
    "                    ct = ct.to(device)\n",
    "                    mask = mask.to(device)\n",
    "                    \n",
    "                    yield_list.append([ct, mask])\n",
    "                    batch_count += 1\n",
    "\n",
    "                    if batch_count == self.batch_size:\n",
    "                        yield yield_list\n",
    "                        batch_count = 0\n",
    "                        yield_list = []\n",
    "\n",
    "    def test_generate(self):\n",
    "        for _, __, files in os.walk(self.TEST_DATA_PATH):\n",
    "            for file in files:\n",
    "                ct = np.load(self.TEST_DATA_PATH + file)\n",
    "                mask = np.load(self.TEST_LABEL_PATH + file)\n",
    "\n",
    "                ct = torch.Tensor(ct)\n",
    "                mask = torch.Tensor(mask)\n",
    "                ct = ct.to(device)\n",
    "                mask = mask.to(device)\n",
    "                    \n",
    "                yield [[ct, mask]]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m datagen \u001b[38;5;241m=\u001b[39m DataGenerator(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mtrain_generate(datagen\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m()) \n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m, in \u001b[0;36mDataGenerator.train_generate\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m     17\u001b[0m batch_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     18\u001b[0m yield_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     20\u001b[0m         ct \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mROOT_DATA_PATH \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m         mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mROOT_LABEL_PATH \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "datagen = DataGenerator(batch_size=1)\n",
    "iter = datagen.train_generate(datagen.__len__()) \n",
    "data = next(iter)\n",
    "print(data[0][0], data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = DataGenerator(batch_size=1)\n",
    "iter = datagen.test_generate() \n",
    "data = next(iter)\n",
    "print(data[0][0], data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in data[0][0]:\n",
    "#     print(row)\n",
    "\n",
    "data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class DoubleConv(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Helper Class which implements the intermediate Convolutions\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.step = torch.nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "                                        torch.nn.ReLU(),\n",
    "                                        torch.nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "                                        torch.nn.ReLU())\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.step(X)\n",
    "\n",
    "\n",
    "class UNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This class implements a UNet for the Segmentation\n",
    "    We use 3 down- and 3 UpConvolutions and two Convolutions in each step\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Sets up the U-Net Structure\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        ############# DOWN #####################\n",
    "        self.layer1 = DoubleConv(1, 64)\n",
    "        self.layer2 = DoubleConv(64, 128)\n",
    "        self.layer3 = DoubleConv(128, 256)\n",
    "        self.layer4 = DoubleConv(256, 512)\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        ############## UP #######################\n",
    "        self.layer5 = DoubleConv(512 + 256, 256)\n",
    "        self.layer6 = DoubleConv(256+128, 128)\n",
    "        self.layer7 = DoubleConv(128+64, 64)\n",
    "        self.layer8 = torch.nn.Conv2d(64, 1, 1)\n",
    "        #########################################\n",
    "\n",
    "        self.maxpool = torch.nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        ####### DownConv 1#########\n",
    "        x1 = self.layer1(x)\n",
    "        x1m = self.maxpool(x1)\n",
    "        ###########################\n",
    "        \n",
    "        ####### DownConv 2#########        \n",
    "        x2 = self.layer2(x1m)\n",
    "        x2m = self.maxpool(x2)\n",
    "        ###########################\n",
    "\n",
    "        ####### DownConv 3#########        \n",
    "        x3 = self.layer3(x2m)\n",
    "        x3m = self.maxpool(x3)\n",
    "        ###########################\n",
    "        \n",
    "        ##### Intermediate Layer ## \n",
    "        x4 = self.layer4(x3m)\n",
    "        ###########################\n",
    "\n",
    "        ####### UpCONV 1#########        \n",
    "        x5 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x4)  # Upsample with a factor of 2\n",
    "        #x5 = torch.nn.ConvTranspose2d(512, 512, 2, 2)(x4)\n",
    "        x5 = torch.cat([x5, x3], dim=1)  # Skip-Connection\n",
    "        x5 = self.layer5(x5)\n",
    "        ###########################\n",
    "\n",
    "        ####### UpCONV 2#########        \n",
    "        x6 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x5)        \n",
    "        #x6 = torch.nn.ConvTranspose2d(256, 256, 2, 2)(x5)\n",
    "        x6 = torch.cat([x6, x2], dim=1)  # Skip-Connection    \n",
    "        x6 = self.layer6(x6)\n",
    "        ###########################\n",
    "        \n",
    "        ####### UpCONV 3#########        \n",
    "        x7 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x6)\n",
    "        #x7 = torch.nn.ConvTranspose2d(128, 128, 2, 2)(x6)\n",
    "        x7 = torch.cat([x7, x1], dim=1)       \n",
    "        x7 = self.layer7(x7)\n",
    "        x7 = np.where(x7 > 0.5, 1, 0)\n",
    "        ###########################\n",
    "        \n",
    "        ####### Predicted segmentation#########        \n",
    "        ret = self.layer8(x7)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet()\n",
    "model =  smp.Unet(\n",
    "    encoder_name=\"efficientnet-b1\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = datagen.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(15):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(datagen.train_generate(size), 0)):\n",
    "        \n",
    "        inputs, labels = data[0][0], data[0][1]\n",
    "        # inputs = inputs.to(device)\n",
    "        # labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        # outputs = outputs.cpu().numpy()\n",
    "        # outputs = np.where(outputs > 0.5, 1.0, 0.0)\n",
    "        # labels = labels.cpu().numpy()\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "        if i == datagen.__len__()-1:\n",
    "            break\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceScore(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    class to compute the Dice Loss\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pred, mask):\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        pred = torch.flatten(pred)\n",
    "        mask = torch.flatten(mask)\n",
    "\n",
    "        counter = (pred * mask).sum()  # Counter\n",
    "        print(counter)\n",
    "        denum = pred.sum() + mask.sum()\n",
    "        print(denum)  # denominator\n",
    "        dice = (2*counter)/denum\n",
    "\n",
    "        return dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "for i, data in tqdm(enumerate(datagen.test_generate(), 0)):\n",
    "        \n",
    "    input, label = data[0][0], data[0][1]\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        pred = model(input)\n",
    "        \n",
    "    pred = pred.cpu().numpy()\n",
    "    pred = np.where(pred < 0.5, 0, 1)\n",
    "\n",
    "    preds.append(pred)\n",
    "    labels.append(label.cpu().numpy())\n",
    "    \n",
    "preds = np.array(preds)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_score = DiceScore()(torch.from_numpy(preds), torch.from_numpy(labels))\n",
    "print(f\"The Val Dice Score is: {dice_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

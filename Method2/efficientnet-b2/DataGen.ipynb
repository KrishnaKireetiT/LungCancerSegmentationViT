{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.train_data_size = (0,57)\n",
    "        self.test_data_size = (57, 63)\n",
    "        self.ROOT_DATA_PATH = 'Task06_Lung/Preprocessed/train/data/'\n",
    "        self.ROOT_LABEL_PATH = 'Task06_Lung/Preprocessed/train/label/'\n",
    "        self.TEST_DATA_PATH = 'Task06_Lung/Preprocessed/test/data/'\n",
    "        self.TEST_LABEL_PATH = 'Task06_Lung/Preprocessed/test/label/'\n",
    "\n",
    "    def __len__(self):\n",
    "        for _, __, files in os.walk(self.ROOT_DATA_PATH):\n",
    "            return len(files)\n",
    "\n",
    "    def train_generate(self, size):\n",
    "        while True:\n",
    "            batch_count = 0\n",
    "            yield_list = []\n",
    "            for i in range(size):\n",
    "                    ct = np.load(self.ROOT_DATA_PATH + str(i) + \".npy\")\n",
    "                    mask = np.load(self.ROOT_LABEL_PATH + str(i) + \".npy\")\n",
    "\n",
    "                    ct = torch.Tensor(ct)\n",
    "                    mask = torch.Tensor(mask)\n",
    "                    ct = ct.to(device)\n",
    "                    mask = mask.to(device)\n",
    "                    \n",
    "                    yield_list.append([ct, mask])\n",
    "                    batch_count += 1\n",
    "\n",
    "                    if batch_count == self.batch_size:\n",
    "                        yield yield_list\n",
    "                        batch_count = 0\n",
    "                        yield_list = []\n",
    "\n",
    "    def test_generate(self):\n",
    "        for _, __, files in os.walk(self.TEST_DATA_PATH):\n",
    "            for file in files:\n",
    "                ct = np.load(self.TEST_DATA_PATH + file)\n",
    "                mask = np.load(self.TEST_LABEL_PATH + file)\n",
    "\n",
    "                ct = torch.Tensor(ct)\n",
    "                mask = torch.Tensor(mask)\n",
    "                ct = ct.to(device)\n",
    "                mask = mask.to(device)\n",
    "                    \n",
    "                yield [[ct, mask]]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0040, 0.0070, 0.0113,  ..., 0.0060, 0.0110, 0.0086],\n",
      "          [0.0078, 0.0035, 0.0050,  ..., 0.0116, 0.0056, 0.0084],\n",
      "          [0.0054, 0.0088, 0.0122,  ..., 0.0036, 0.0081, 0.0057]]]],\n",
      "       device='cuda:0') tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "datagen = DataGenerator(batch_size=1)\n",
    "iter = datagen.train_generate(datagen.__len__()) \n",
    "data = next(iter)\n",
    "print(data[0][0], data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0370, 0.0397, 0.0413,  ..., 0.0106, 0.0086, 0.0121],\n",
      "          [0.0423, 0.0366, 0.0430,  ..., 0.0040, 0.0058, 0.0085],\n",
      "          [0.0271, 0.0439, 0.0377,  ..., 0.0172, 0.0122, 0.0163],\n",
      "          ...,\n",
      "          [0.0567, 0.0294, 0.0593,  ..., 0.0084, 0.0119, 0.0074],\n",
      "          [0.0502, 0.0574, 0.0608,  ..., 0.0118, 0.0103, 0.0052],\n",
      "          [0.0594, 0.0557, 0.0480,  ..., 0.0063, 0.0095, 0.0129]]]],\n",
      "       device='cuda:0') tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "datagen = DataGenerator(batch_size=1)\n",
    "iter = datagen.test_generate() \n",
    "data = next(iter)\n",
    "print(data[0][0], data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256, 256])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for row in data[0][0]:\n",
    "#     print(row)\n",
    "\n",
    "data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class DoubleConv(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Helper Class which implements the intermediate Convolutions\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.step = torch.nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "                                        torch.nn.ReLU(),\n",
    "                                        torch.nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "                                        torch.nn.ReLU())\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.step(X)\n",
    "\n",
    "\n",
    "class UNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This class implements a UNet for the Segmentation\n",
    "    We use 3 down- and 3 UpConvolutions and two Convolutions in each step\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Sets up the U-Net Structure\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        ############# DOWN #####################\n",
    "        self.layer1 = DoubleConv(1, 64)\n",
    "        self.layer2 = DoubleConv(64, 128)\n",
    "        self.layer3 = DoubleConv(128, 256)\n",
    "        self.layer4 = DoubleConv(256, 512)\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        ############## UP #######################\n",
    "        self.layer5 = DoubleConv(512 + 256, 256)\n",
    "        self.layer6 = DoubleConv(256+128, 128)\n",
    "        self.layer7 = DoubleConv(128+64, 64)\n",
    "        self.layer8 = torch.nn.Conv2d(64, 1, 1)\n",
    "        #########################################\n",
    "\n",
    "        self.maxpool = torch.nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        ####### DownConv 1#########\n",
    "        x1 = self.layer1(x)\n",
    "        x1m = self.maxpool(x1)\n",
    "        ###########################\n",
    "        \n",
    "        ####### DownConv 2#########        \n",
    "        x2 = self.layer2(x1m)\n",
    "        x2m = self.maxpool(x2)\n",
    "        ###########################\n",
    "\n",
    "        ####### DownConv 3#########        \n",
    "        x3 = self.layer3(x2m)\n",
    "        x3m = self.maxpool(x3)\n",
    "        ###########################\n",
    "        \n",
    "        ##### Intermediate Layer ## \n",
    "        x4 = self.layer4(x3m)\n",
    "        ###########################\n",
    "\n",
    "        ####### UpCONV 1#########        \n",
    "        x5 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x4)  # Upsample with a factor of 2\n",
    "        #x5 = torch.nn.ConvTranspose2d(512, 512, 2, 2)(x4)\n",
    "        x5 = torch.cat([x5, x3], dim=1)  # Skip-Connection\n",
    "        x5 = self.layer5(x5)\n",
    "        ###########################\n",
    "\n",
    "        ####### UpCONV 2#########        \n",
    "        x6 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x5)        \n",
    "        #x6 = torch.nn.ConvTranspose2d(256, 256, 2, 2)(x5)\n",
    "        x6 = torch.cat([x6, x2], dim=1)  # Skip-Connection    \n",
    "        x6 = self.layer6(x6)\n",
    "        ###########################\n",
    "        \n",
    "        ####### UpCONV 3#########        \n",
    "        x7 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x6)\n",
    "        #x7 = torch.nn.ConvTranspose2d(128, 128, 2, 2)(x6)\n",
    "        x7 = torch.cat([x7, x1], dim=1)       \n",
    "        x7 = self.layer7(x7)\n",
    "        x7 = np.where(x7 > 0.5, 1, 0)\n",
    "        ###########################\n",
    "        \n",
    "        ####### Predicted segmentation#########        \n",
    "        ret = self.layer8(x7)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet()\n",
    "model =  smp.Unet(\n",
    "    encoder_name=\"resnet108\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = datagen.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2004it [02:15, 23.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [03:15, 17.78it/s]\n",
      "2004it [01:01, 32.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  2000] loss: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [01:47, 32.41it/s]\n",
      "2004it [01:01, 31.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  2000] loss: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [01:49, 31.93it/s]\n",
      "2004it [01:02, 32.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  2000] loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [01:48, 32.22it/s]\n",
      "2004it [01:02, 31.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  2000] loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [01:48, 32.20it/s]\n",
      "2004it [01:02, 32.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,  2000] loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [01:48, 32.21it/s]\n",
      "2004it [01:02, 32.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,  2000] loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [01:48, 32.18it/s]\n",
      "2004it [01:02, 32.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,  2000] loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [01:48, 32.19it/s]\n",
      "2003it [01:02, 31.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,  2000] loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [01:48, 32.16it/s]\n",
      "2004it [01:02, 32.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,  2000] loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [01:48, 32.14it/s]\n",
      "2004it [01:02, 32.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,  2000] loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [01:48, 32.23it/s]\n",
      "2004it [01:02, 32.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12,  2000] loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [01:48, 32.22it/s]\n",
      "2004it [01:02, 32.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13,  2000] loss: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [01:47, 32.24it/s]\n",
      "2004it [01:02, 32.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,  2000] loss: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [01:47, 32.27it/s]\n",
      "2004it [01:02, 32.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15,  2000] loss: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [01:48, 32.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(datagen.train_generate(size), 0)):\n",
    "        \n",
    "        inputs, labels = data[0][0], data[0][1]\n",
    "        # inputs = inputs.to(device)\n",
    "        # labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        # outputs = outputs.cpu().numpy()\n",
    "        # outputs = np.where(outputs > 0.5, 1.0, 0.0)\n",
    "        # labels = labels.cpu().numpy()\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "        if i == datagen.__len__()-1:\n",
    "            break\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceScore(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    class to compute the Dice Loss\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pred, mask):\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        pred = torch.flatten(pred)\n",
    "        mask = torch.flatten(mask)\n",
    "\n",
    "        counter = (pred * mask).sum()  # Counter\n",
    "        print(counter)\n",
    "        denum = pred.sum() + mask.sum()\n",
    "        print(denum)  # denominator\n",
    "        dice = (2*counter)/denum\n",
    "\n",
    "        return dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "860it [00:17, 49.08it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "for i, data in tqdm(enumerate(datagen.test_generate(), 0)):\n",
    "        \n",
    "    input, label = data[0][0], data[0][1]\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        pred = model(input)\n",
    "        \n",
    "    pred = pred.cpu().numpy()\n",
    "    pred = np.where(pred < 0.5, 0, 1)\n",
    "\n",
    "    preds.append(pred)\n",
    "    labels.append(label.cpu().numpy())\n",
    "    \n",
    "preds = np.array(preds)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10225.)\n",
      "tensor(57852.7500)\n",
      "The Val Dice Score is: 0.3534836173057556\n"
     ]
    }
   ],
   "source": [
    "dice_score = DiceScore()(torch.from_numpy(preds), torch.from_numpy(labels))\n",
    "print(f\"The Val Dice Score is: {dice_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_path, label_path):\n",
    "        self.data_path = data_path\n",
    "        self.label_path = label_path\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.data_path))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ct = np.load(os.path.join(self.data_path, f\"{idx}.npy\"))\n",
    "        mask = np.load(os.path.join(self.label_path, f\"{idx}.npy\"))\n",
    "\n",
    "        ct = torch.Tensor(ct).to(self.device)\n",
    "        mask = torch.Tensor(mask).to(self.device)\n",
    "\n",
    "        return ct, mask\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.ROOT_DATA_PATH = 'Task06_Lung/Preprocessed/train/data/'\n",
    "        self.ROOT_LABEL_PATH = 'Task06_Lung/Preprocessed/train/label/'\n",
    "        self.TEST_DATA_PATH = 'Task06_Lung/Preprocessed/test/data/'\n",
    "        self.TEST_LABEL_PATH = 'Task06_Lung/Preprocessed/test/label/'\n",
    "\n",
    "    def train_loader(self):\n",
    "        dataset = CustomDataset(self.ROOT_DATA_PATH, self.ROOT_LABEL_PATH)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def test_loader(self):\n",
    "        dataset = CustomDataset(self.TEST_DATA_PATH, self.TEST_LABEL_PATH)\n",
    "        return DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the batch size\n",
    "batch_size = 4\n",
    "\n",
    "# Create an instance of the DataGenerator\n",
    "data_generator = DataGenerator(batch_size)\n",
    "\n",
    "# Get the training DataLoader\n",
    "train_loader = data_generator.train_loader()\n",
    "\n",
    "# Get the testing DataLoader\n",
    "test_loader = data_generator.test_loader()\n",
    "\n",
    "# # Iterate through the training DataLoader\n",
    "# for batch_idx, (ct, mask) in enumerate(train_loader):\n",
    "#     # Your training code here\n",
    "#     print(f\"Batch {batch_idx + 1}: CT Shape: {ct.shape}, Mask Shape: {mask.shape}\")\n",
    "\n",
    "# # # Iterate through the testing DataLoader\n",
    "# # for batch_idx, (ct, mask) in enumerate(test_loader):\n",
    "# #     # Your testing code here\n",
    "# #     print(f\"Batch {batch_idx + 1}: CT Shape: {ct.shape}, Mask Shape: {mask.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataGenerator:\n",
    "#     def __init__(self, batch_size):\n",
    "#         self.batch_size = batch_size\n",
    "#         self.ROOT_DATA_PATH = 'Task06_Lung/Preprocessed/train/data/'\n",
    "#         self.ROOT_LABEL_PATH = 'Task06_Lung/Preprocessed/train/label/'\n",
    "#         self.TEST_DATA_PATH = 'Task06_Lung/Preprocessed/test/data/'\n",
    "#         self.TEST_LABEL_PATH = 'Task06_Lung/Preprocessed/test/label/'\n",
    "\n",
    "#     def __len__(self):\n",
    "#         for _, __, files in os.walk(self.ROOT_DATA_PATH):\n",
    "#             return len(files)\n",
    "\n",
    "#     def train_generate(self, size):\n",
    "#         while True:\n",
    "#             batch_count = 0\n",
    "#             yield_list = []\n",
    "#             for i in range(size):\n",
    "#                     ct = np.load(self.ROOT_DATA_PATH + str(i) + \".npy\")\n",
    "#                     mask = np.load(self.ROOT_LABEL_PATH + str(i) + \".npy\")\n",
    "\n",
    "#                     ct = torch.Tensor(ct)\n",
    "#                     mask = torch.Tensor(mask)\n",
    "#                     ct = ct.to(device)\n",
    "#                     mask = mask.to(device)\n",
    "                    \n",
    "#                     yield_list.append([ct, mask])\n",
    "#                     batch_count += 1\n",
    "\n",
    "#                     if batch_count == self.batch_size:\n",
    "#                         yield yield_list\n",
    "#                         batch_count = 0\n",
    "#                         yield_list = []\n",
    "\n",
    "#     def test_generate(self):\n",
    "#         for _, __, files in os.walk(self.TEST_DATA_PATH):\n",
    "#             for file in files:\n",
    "#                 ct = np.load(self.TEST_DATA_PATH + file)\n",
    "#                 mask = np.load(self.TEST_LABEL_PATH + file)\n",
    "\n",
    "#                 ct = torch.Tensor(ct)\n",
    "#                 mask = torch.Tensor(mask)\n",
    "#                 ct = ct.to(device)\n",
    "#                 mask = mask.to(device)\n",
    "                    \n",
    "#                 yield [[ct, mask]]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# datagen = DataGenerator(batch_size=1)\n",
    "# iter = datagen.train_generate(datagen.__len__()) \n",
    "# data = next(iter)\n",
    "# print(data[0][0], data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen = DataGenerator(batch_size=1)\n",
    "# iter = datagen.test_generate() \n",
    "# data = next(iter)\n",
    "# print(data[0][0], data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for row in data[0][0]:\n",
    "# #     print(row)\n",
    "\n",
    "# data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# class DoubleConv(torch.nn.Module):\n",
    "#     \"\"\"\n",
    "#     Helper Class which implements the intermediate Convolutions\n",
    "#     \"\"\"\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "        \n",
    "#         super().__init__()\n",
    "#         self.step = torch.nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "#                                         torch.nn.ReLU(),\n",
    "#                                         torch.nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "#                                         torch.nn.ReLU())\n",
    "        \n",
    "#     def forward(self, X):\n",
    "#         return self.step(X)\n",
    "\n",
    "\n",
    "# class UNet(torch.nn.Module):\n",
    "#     \"\"\"\n",
    "#     This class implements a UNet for the Segmentation\n",
    "#     We use 3 down- and 3 UpConvolutions and two Convolutions in each step\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self):\n",
    "#         \"\"\"Sets up the U-Net Structure\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "        \n",
    "        \n",
    "#         ############# DOWN #####################\n",
    "#         self.layer1 = DoubleConv(1, 64)\n",
    "#         self.layer2 = DoubleConv(64, 128)\n",
    "#         self.layer3 = DoubleConv(128, 256)\n",
    "#         self.layer4 = DoubleConv(256, 512)\n",
    "\n",
    "#         #########################################\n",
    "\n",
    "#         ############## UP #######################\n",
    "#         self.layer5 = DoubleConv(512 + 256, 256)\n",
    "#         self.layer6 = DoubleConv(256+128, 128)\n",
    "#         self.layer7 = DoubleConv(128+64, 64)\n",
    "#         self.layer8 = torch.nn.Conv2d(64, 1, 1)\n",
    "#         #########################################\n",
    "\n",
    "#         self.maxpool = torch.nn.MaxPool2d(2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         ####### DownConv 1#########\n",
    "#         x1 = self.layer1(x)\n",
    "#         x1m = self.maxpool(x1)\n",
    "#         ###########################\n",
    "        \n",
    "#         ####### DownConv 2#########        \n",
    "#         x2 = self.layer2(x1m)\n",
    "#         x2m = self.maxpool(x2)\n",
    "#         ###########################\n",
    "\n",
    "#         ####### DownConv 3#########        \n",
    "#         x3 = self.layer3(x2m)\n",
    "#         x3m = self.maxpool(x3)\n",
    "#         ###########################\n",
    "        \n",
    "#         ##### Intermediate Layer ## \n",
    "#         x4 = self.layer4(x3m)\n",
    "#         ###########################\n",
    "\n",
    "#         ####### UpCONV 1#########        \n",
    "#         x5 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x4)  # Upsample with a factor of 2\n",
    "#         x5 = torch.nn.ConvTranspose2d(512, 512, 2, 2)(x4)\n",
    "#         x5 = torch.cat([x5, x3], dim=1)  # Skip-Connection\n",
    "#         x5 = self.layer5(x5)\n",
    "#         ###########################\n",
    "\n",
    "#         ####### UpCONV 2#########        \n",
    "#         x6 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x5)        \n",
    "#         x6 = torch.nn.ConvTranspose2d(256, 256, 2, 2)(x5)\n",
    "#         x6 = torch.cat([x6, x2], dim=1)  # Skip-Connection    \n",
    "#         x6 = self.layer6(x6)\n",
    "#         ###########################\n",
    "        \n",
    "#         ####### UpCONV 3#########        \n",
    "#         x7 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x6)\n",
    "#         x7 = torch.nn.ConvTranspose2d(128, 128, 2, 2)(x6)\n",
    "#         x7 = torch.cat([x7, x1], dim=1)       \n",
    "#         x7 = self.layer7(x7)\n",
    "#         ###########################\n",
    "        \n",
    "#         ####### Predicted segmentation#########        \n",
    "#         ret = self.layer8(x7)\n",
    "#         return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet()\n",
    "model =  smp.Unet(\n",
    "    encoder_name=\"efficientnet-b1\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.rand(1,1,256,256)\n",
    "data = torch.Tensor(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fvcore.nn import FlopCountAnalysis\n",
    "# flops = FlopCountAnalysis(model, train_loader[0])\n",
    "# flops.total() // 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flops.by_operator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flops.by_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flops.by_module_and_operator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = datagen.__len__()\n",
    "size = train_loader.__len__()\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_idx, (ct, mask) in enumerate(train_loader):\n",
    "        # Move data to the appropriate device\n",
    "        ct, mask = ct.to(device), mask.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(ct)\n",
    "        # outputs = 1 if outputs > 0.5 else 0\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, mask)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCH}, Average Loss: {average_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(EPOCH):  # loop over the dataset multiple times\n",
    "\n",
    "#     running_loss = 0.0\n",
    "#     for i, (ct, mask) in tqdm(enumerate(train_loader)):\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         outputs = model(ct)\n",
    "#         # labels = labels.cpu().numpy()\n",
    "#         loss = loss_fn(outputs, mask)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # print statistics\n",
    "#         running_loss += loss.item()\n",
    "#         if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "#             running_loss = 0.0\n",
    "\n",
    "#         if i == size:\n",
    "#             break\n",
    "\n",
    "\n",
    "# print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceScore(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    class to compute the Dice Loss\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pred, mask):\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        pred = torch.flatten(pred)\n",
    "        mask = torch.flatten(mask)\n",
    "\n",
    "        counter = (pred * mask).sum()  # Counter\n",
    "        print(counter)\n",
    "        denum = pred.sum() + mask.sum()\n",
    "        print(denum)  # denominator\n",
    "        dice = (2*counter)/denum\n",
    "\n",
    "        return dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "for batch_idx, (ct, mask) in enumerate(test_loader):\n",
    "\n",
    "    ct, mask = ct.to(device), mask.to(device)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        pred = model(ct)\n",
    "        \n",
    "    pred = pred.cpu().numpy()\n",
    "    pred = np.where(pred < 0.5, 0, 1)\n",
    "\n",
    "    preds.append(pred)\n",
    "    labels.append(mask.cpu().numpy())\n",
    "    \n",
    "preds = np.array(preds)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_score = DiceScore()(torch.from_numpy(preds), torch.from_numpy(labels))\n",
    "print(f\"The Val Dice Score is: {dice_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(preds)):\n",
    "    if preds[i].sum() > 0:\n",
    "        print(preds[i].sum(), labels[i].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from celluloid import Camera\n",
    "from IPython.display import HTML\n",
    "fig = plt.figure()\n",
    "camera = Camera(fig)\n",
    "\n",
    "for i in range(len(preds)):  # axial view\n",
    "    plt.imshow(preds[i][0, 0, :, :], cmap=\"bone\")\n",
    "    plt.axis(\"off\")\n",
    "    camera.snap()\n",
    "\n",
    "animation = camera.animate()\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from celluloid import Camera\n",
    "from IPython.display import HTML\n",
    "fig = plt.figure()\n",
    "camera = Camera(fig)\n",
    "\n",
    "for i in range(len(preds)):  # axial view\n",
    "    plt.imshow(labels[i][0, 0, :, :], cmap=\"bone\")\n",
    "    plt.axis(\"off\")\n",
    "    camera.snap()\n",
    "\n",
    "animation = camera.animate()\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

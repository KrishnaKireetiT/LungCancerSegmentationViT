{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "from einops.layers.torch import Rearrange\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_patches, projection_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        positions = torch.arange(x.shape[1], device=x.device).unsqueeze(0)\n",
    "        encoded_positions = self.embedding(positions)\n",
    "        return x + encoded_positions\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_units, dropout_rate):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        for units in hidden_units:\n",
    "            layers.extend([\n",
    "                nn.Linear(input_dim, units),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            input_dim = units\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class TokenLearner(nn.Module):\n",
    "    def __init__(self, num_tokens):\n",
    "        super(TokenLearner, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=num_tokens, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=num_tokens, out_channels=num_tokens, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=num_tokens, out_channels=num_tokens, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=num_tokens, out_channels=1, kernel_size=3, padding=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"TokenLearner\")\n",
    "        # print(x.shape)\n",
    "        x = F.gelu(self.conv1(x))\n",
    "        # print(x.shape)\n",
    "        x = F.gelu(self.conv2(x))\n",
    "        # print(x.shape)\n",
    "        x = F.gelu(self.conv3(x))\n",
    "        # print(x.shape)\n",
    "        x = self.sigmoid(self.conv4(x))\n",
    "        # print(x.shape)\n",
    "        # x = x.view(x.size(0), x.size(1), -1)\n",
    "        # print(x.shape)\n",
    "        # x = x.permute(0, 2, 1)  # Permute to match TensorFlow's behavior\n",
    "        # print(x.shape)\n",
    "        # print(\"TokenLearner Done\")\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, mlp_units, dropout_rate):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.multihead_attention = nn.MultiheadAttention(input_dim, num_heads, dropout=dropout_rate)\n",
    "        self.mlp = MLP(input_dim, mlp_units, dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"Transformer\")\n",
    "        # print(x.shape)\n",
    "        attention_output, _ = self.multihead_attention(x, x, x)\n",
    "        # print(x.shape)\n",
    "        x = x + attention_output\n",
    "        # print(x.shape)\n",
    "        x = x + self.mlp(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "class ViTClassifier(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, num_patches, projection_dim, num_heads, mlp_units, dropout_rate, num_classes, use_token_learner=True, token_learner_units=4):\n",
    "        super(ViTClassifier, self).__init__()\n",
    "        self.patch_embedding = nn.Conv2d(in_channels=1, out_channels=projection_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.positional_embedding = PositionalEmbedding(num_patches, projection_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.transformer_layers = nn.ModuleList([Transformer(projection_dim, num_heads, mlp_units, dropout_rate) for _ in range(6)])\n",
    "        self.use_token_learner = use_token_learner\n",
    "        self.token_learner = TokenLearner(token_learner_units) if use_token_learner else None\n",
    "        self.layer_norm = nn.LayerNorm(projection_dim)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(projection_dim, num_classes)\n",
    "        self.projection_dim = projection_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.patch_embedding(x)\n",
    "        B, _, H, W = x.shape\n",
    "        # print(x.shape)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        # print(x.shape)\n",
    "        x = self.positional_embedding(x)\n",
    "        # print(x.shape)\n",
    "        x = self.dropout(x)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        for transformer in self.transformer_layers:\n",
    "            x = transformer(x)\n",
    "            # print(x.shape)\n",
    "        # print(x.shape)\n",
    "\n",
    "        if self.use_token_learner:\n",
    "            x = x.permute(0, 2, 1).unsqueeze(1)  # Adjust shape for TokenLearner\n",
    "            # print(x.shape)\n",
    "            x = self.token_learner(x)\n",
    "            # print(x.shape)\n",
    "            x = x.squeeze(1).permute(0, 2, 1)  # Adjust shape back\n",
    "            # print(x.shape)\n",
    "        \n",
    "        # print(x.shape)\n",
    "        return x\n",
    "        \n",
    "        # x = self.layer_norm(x)\n",
    "        # x = self.global_avg_pool(x).squeeze(2)\n",
    "        # x = self.classifier(x)\n",
    "        # return x\n",
    "\n",
    "# # Create the ViT classifier model\n",
    "# model = ViTClassifier(\n",
    "#     image_size=256,\n",
    "#     patch_size=8,\n",
    "#     num_patches=196,\n",
    "#     projection_dim=256,\n",
    "#     num_heads=8,\n",
    "#     mlp_units=[256, 128],\n",
    "#     dropout_rate=0.1,\n",
    "#     num_classes=4,\n",
    "#     use_token_learner=True,\n",
    "#     token_learner_units=4\n",
    "# )\n",
    "\n",
    "# # Print model summary\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, patch_size, num_patches, hidden_dim, num_heads, mlp_dim, dropout=0.1):\n",
    "        super(ViTBlock, self).__init__()\n",
    "        self.patch_embedding = nn.Conv2d(in_channels, out_channels, kernel_size=patch_size, stride=patch_size)\n",
    "        self.position_embedding = nn.Parameter(torch.randn(1, num_patches, out_channels))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, out_channels))\n",
    "        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(out_channels, num_heads, dim_feedforward=mlp_dim, dropout=dropout, batch_first=True), num_layers=1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"New Call\")\n",
    "        \n",
    "        # print(\"Encoder 1\", x.shape)\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.patch_embedding(x)  # B, out_channels, H', W'\n",
    "        # print(\"Encoder 2\", x.shape)\n",
    "        \n",
    "        x = x.flatten(2).transpose(1, 2)  # B, (H' * W'), out_channels\n",
    "        # print(\"Encoder 3\", x.shape)\n",
    "        \n",
    "        # cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        # print(\"Encoder 4\", cls_tokens.shape, x.shape)\n",
    "        \n",
    "        # x = torch.cat((cls_tokens, x), dim=1)\n",
    "        # print(\"Encoder 5\", x.shape)\n",
    "\n",
    "        x += self.position_embedding\n",
    "        # print(\"Encoder 6\", x.shape)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        # print(\"Encoder 7\", x.shape)\n",
    "        \n",
    "        x = self.transformer(x)\n",
    "        # print(\"Encoder 8\", x.shape)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ViTUnet(nn.Module):\n",
    "    def __init__(self, num_classes=1, in_channels=3, patch_size=16, vit_hidden_dim=256, vit_num_heads=8, vit_mlp_dim=512, dropout=0.1):\n",
    "        super(ViTUnet, self).__init__()\n",
    "\n",
    "        num_patches = (256 // patch_size) ** 2\n",
    "        self.vit_block1 = ViTClassifier(image_size=256, patch_size=patch_size, num_patches=num_patches, projection_dim=vit_hidden_dim, num_heads=vit_num_heads,\n",
    "    mlp_units=[256, 256], dropout_rate=dropout, num_classes=num_classes, use_token_learner=True, token_learner_units=4)\n",
    "        # self.vit_block1 = ViTBlock(in_channels, vit_hidden_dim, patch_size, num_patches, vit_hidden_dim, vit_num_heads, vit_mlp_dim, dropout)\n",
    "        # self.vit_block2 = ViTBlock(vit_hidden_dim, vit_hidden_dim, patch_size // 2, num_patches // 4, vit_hidden_dim, vit_num_heads, vit_mlp_dim, dropout)\n",
    "        # self.vit_block3 = ViTBlock(vit_hidden_dim, vit_hidden_dim, patch_size // 2, num_patches // 16, vit_hidden_dim, vit_num_heads, vit_mlp_dim, dropout)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"New Iteration\")\n",
    "        # print(\"Decoder 1\", x.shape)\n",
    "        x1 = self.vit_block1(x)\n",
    "        # print(x1.shape)\n",
    "        x1 = x1.unsqueeze(1)\n",
    "        # x2 = self.vit_block2(x1.unsqueeze(1)).squeeze(1)\n",
    "        # print(\"Decoder 3\", x2.shape, x2.unsqueeze(1).shape )\n",
    "        # x3 = self.vit_block3(x2.unsqueeze(1)).squeeze(1)\n",
    "        # print(\"Decoder 4\", x3.shape)\n",
    "        # x = F.interpolate(x1.unsqueeze(1), scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        # print(\"Decoder 5\", x.shape)\n",
    "        # x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        # print(\"Decoder 6\", x1.shape)\n",
    "        x = self.decoder(x1)\n",
    "        # print(\"Decoder 7\", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = ['efficientnet-b4', 'efficientnet-b3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark = pd.DataFrame(columns=['model_name', 'epochs', 'gflops', 'dice_score', 'iou_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_path, label_path):\n",
    "        self.data_path = data_path\n",
    "        self.label_path = label_path\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.data_path))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ct = np.load(os.path.join(self.data_path, f\"{idx}.npy\"))\n",
    "        mask = np.load(os.path.join(self.label_path, f\"{idx}.npy\"))\n",
    "\n",
    "        ct = torch.Tensor(ct).to(self.device)\n",
    "        mask = torch.Tensor(mask).to(self.device)\n",
    "\n",
    "        return ct, mask\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.ROOT_DATA_PATH = 'Task06_Lung/Preprocessed/all/data/'\n",
    "        self.ROOT_LABEL_PATH = 'Task06_Lung/Preprocessed/all/label/'\n",
    "        self.TEST_DATA_PATH = 'Task06_Lung/Preprocessed/test/data/'\n",
    "        self.TEST_LABEL_PATH = 'Task06_Lung/Preprocessed/test/label/'\n",
    "\n",
    "    def train_loader(self):\n",
    "        dataset = CustomDataset(self.ROOT_DATA_PATH, self.ROOT_LABEL_PATH)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def test_loader(self):\n",
    "        dataset = CustomDataset(self.TEST_DATA_PATH, self.TEST_LABEL_PATH)\n",
    "        return DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "data_generator = DataGenerator(batch_size)\n",
    "\n",
    "train_loader = data_generator.train_loader()\n",
    "\n",
    "test_loader = data_generator.test_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceScore(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    class to compute the Dice Loss\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pred, mask):\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        pred = torch.flatten(pred)\n",
    "        mask = torch.flatten(mask)\n",
    "\n",
    "        counter = (pred * mask).sum()  # Counter\n",
    "        denum = pred.sum() + mask.sum()\n",
    "        dice = (2*counter)/denum\n",
    "\n",
    "        return dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(groundtruth_mask, pred_mask):\n",
    "    intersect = np.sum(pred_mask*groundtruth_mask)\n",
    "    union = np.sum(pred_mask) + np.sum(groundtruth_mask) - intersect\n",
    "    iou = np.mean(intersect/union)\n",
    "    return round(iou, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Average Loss: 0.0465\n",
      "Epoch 2/5, Average Loss: 0.0264\n",
      "Epoch 3/5, Average Loss: 0.0264\n",
      "Epoch 4/5, Average Loss: 0.0270\n",
      "Epoch 5/5, Average Loss: 0.0264\n",
      "Dice: tensor(0.)\n",
      "\n",
      "\n",
      "IoU: 0.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::embedding encountered 1 time(s)\n",
      "Unsupported operator aten::add encountered 13 time(s)\n",
      "Unsupported operator aten::div encountered 12 time(s)\n",
      "Unsupported operator aten::unflatten encountered 6 time(s)\n",
      "Unsupported operator aten::mul encountered 24 time(s)\n",
      "Unsupported operator aten::softmax encountered 6 time(s)\n",
      "Unsupported operator aten::gelu encountered 15 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "vit_block1.classifier, vit_block1.global_avg_pool, vit_block1.layer_norm, vit_block1.transformer_layers.0.multihead_attention.out_proj, vit_block1.transformer_layers.1.multihead_attention.out_proj, vit_block1.transformer_layers.2.multihead_attention.out_proj, vit_block1.transformer_layers.3.multihead_attention.out_proj, vit_block1.transformer_layers.4.multihead_attention.out_proj, vit_block1.transformer_layers.5.multihead_attention.out_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flops: 12.0\n"
     ]
    }
   ],
   "source": [
    "# for name in tqdm(models):\n",
    "\n",
    "# #     model =  smp.Unet(\n",
    "# #     encoder_name=name,        \n",
    "# #     encoder_weights=\"imagenet\",     \n",
    "# #     in_channels=1,                  \n",
    "# #     classes=1,                    \n",
    "# # )\n",
    "    \n",
    "model = ViTUnet(num_classes=1, in_channels=1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "torch.device(device=device)\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_idx, (ct, mask) in enumerate(train_loader):\n",
    "        ct, mask = ct.to(device), mask.to(device)\n",
    "\n",
    "        outputs = model(ct)\n",
    "\n",
    "        loss = criterion(outputs, mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCH}, Average Loss: {average_loss:.4f}\")\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "for batch_idx, (ct, mask) in enumerate(test_loader):\n",
    "\n",
    "    ct, mask = ct.to(device), mask.to(device)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        pred = model(ct)\n",
    "        \n",
    "    pred = pred.cpu().numpy()\n",
    "    mask = mask.cpu().numpy()\n",
    "    pred = np.where(pred > 0.5, 1, 0)\n",
    "\n",
    "    preds.append(pred)\n",
    "    labels.append(mask)\n",
    "    \n",
    "preds = np.array(preds)\n",
    "labels = np.array(labels)\n",
    "\n",
    "dice_score = DiceScore()(torch.from_numpy(preds), torch.from_numpy(labels))\n",
    "iou_score = iou(labels, preds)\n",
    "\n",
    "data = torch.rand(4, 1, 256, 256).to(device)\n",
    "flops = FlopCountAnalysis(model, data)\n",
    "print(\"Dice:\",dice_score)\n",
    "print(\"\\n\")\n",
    "print(\"IoU:\",iou_score)\n",
    "print(\"\\n\")\n",
    "print(\"Flops:\",flops.total() // 1e9)\n",
    "\n",
    "    # new_row = {'model_name': name, 'epochs':EPOCH, 'gflops': flops, 'dice_score': dice_score, 'iou_score': iou_score}\n",
    "    # benchmark = pd.concat([benchmark, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = 'benchmark.xlsx'\n",
    "# benchmark.to_excel(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
